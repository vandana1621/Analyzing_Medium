{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Archive  Analysis (Data Cleaning Phase)\n",
    "In this notebook I will clean the data pulled from medium's archive pages with the scrape_master.py file. I will focus on removing duplicate entries and analyzing potential concerns of data consistency.\n",
    "\n",
    "## Where the data came from.\n",
    "\n",
    "I pulled this data from Medium's archive pages. Each archive page is associated to a story-tag and is a collection of Medium timeline cards organized by date.\n",
    "\n",
    "#### Image of the \"data-science\" Archive\n",
    "\n",
    "<img src=\"img/archive.jpg\" width=500>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### How the data was scraped\n",
    "The data was pulled from from  36 popular Medium story-tag archives. Each archive was <b>scraped for each day between Aug 1, 2017 and Aug 1, 2018.</b>\n",
    "\n",
    "These specific dates were chosen because:\n",
    "1. Medium's clap metric was introduced in August 2017, and older posts might not be relevant. \n",
    "2. The popularity of Medium may have grown, so older posts may not generalize to the preformance of posts today. \n",
    "3. The end date was chosen so that newer posts (September) were not included, as they have not had time to mature and accumulate claps.\n",
    "\n",
    "#### 36 Tags Scraped\n",
    "['ai', 'artificial-intelligence',\n",
    " 'blogging', 'business',\n",
    " 'data-science', 'design',\n",
    " 'education', 'entrepreneurship',\n",
    " 'health', 'humor',\n",
    " 'inspiration', 'javascript',\n",
    " 'leadership', 'life',\n",
    " 'life-lessons', 'love',\n",
    " 'machine-learning', 'marketing',\n",
    " 'motivation', 'personal-development',\n",
    " 'poetry', 'politics',\n",
    " 'productivity', 'programming',\n",
    " 'python', 'racism',\n",
    " 'science', 'self-improvement',\n",
    " 'software-engineering', 'startup',\n",
    " 'tech', 'technology',\n",
    " 'travel', 'web-design',\n",
    " 'web-development', 'writing']\n",
    " \n",
    "## Purpose of the Data\n",
    " 1. To <b>create a performance metric for Medium's authors</b>, so they can compare their work to the rest of Medium.\n",
    " 2. To <b>compare the performance of authors and publications</b> on Medium.\n",
    " 3. To <b>create a leaderboard</b> of the top performing authors and publications in each tag .\n",
    " \n",
    " 4. To <b>find the differences that distinguish well-received articles.</b>\n",
    " \n",
    " \n",
    "\n",
    "\n",
    "## Structure of the data\n",
    "- Title\n",
    "- Subtitle \n",
    "- Image (yes/no)\n",
    "- Author\n",
    "- Publication\n",
    "- Year - Month - Day\n",
    "- Tag\n",
    "- Reading Time\n",
    "- Claps\n",
    "- Comment (yes/no)\n",
    "- Story Url\n",
    "- Author URL\n",
    "\n",
    "<img src=\"img/card.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The AI Hierarchy of Needs</td>\n",
       "      <td>As is usually the case with fast-advancing tec...</td>\n",
       "      <td>0</td>\n",
       "      <td>Monica Rogati</td>\n",
       "      <td>Hacker Noon</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ai</td>\n",
       "      <td>6</td>\n",
       "      <td>5.2K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://hackernoon.com/the-ai-hierarchy-of-nee...</td>\n",
       "      <td>https://hackernoon.com/@mrogati?source=tag_arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why will declarative programming rule chatbots...</td>\n",
       "      <td>Creating smart applications</td>\n",
       "      <td>1</td>\n",
       "      <td>Hristo Borisov</td>\n",
       "      <td>Progress NativeChat</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ai</td>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/nativechat/why-will-declara...</td>\n",
       "      <td>https://medium.com/@hristoborisov?source=tag_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Online Animation: Mixamo vs Norah AI</td>\n",
       "      <td>Online animations tools provide game designers...</td>\n",
       "      <td>1</td>\n",
       "      <td>Emma Laurent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ai</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@laurentemma/online-animati...</td>\n",
       "      <td>https://medium.com/@laurentemma?source=tag_arc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                          The AI Hierarchy of Needs   \n",
       "1  Why will declarative programming rule chatbots...   \n",
       "2               Online Animation: Mixamo vs Norah AI   \n",
       "\n",
       "                                            Subtitle  Image          Author  \\\n",
       "0  As is usually the case with fast-advancing tec...      0   Monica Rogati   \n",
       "1                        Creating smart applications      1  Hristo Borisov   \n",
       "2  Online animations tools provide game designers...      1    Emma Laurent   \n",
       "\n",
       "           Publication  Year  Month  Day Tag  Reading_Time Claps  Comment  \\\n",
       "0          Hacker Noon  2017      8    1  ai             6  5.2K        0   \n",
       "1  Progress NativeChat  2017      8    1  ai             7   150        0   \n",
       "2                  NaN  2017      8    1  ai             5    12        0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://hackernoon.com/the-ai-hierarchy-of-nee...   \n",
       "1  https://medium.com/nativechat/why-will-declara...   \n",
       "2  https://medium.com/@laurentemma/online-animati...   \n",
       "\n",
       "                                          Author_url  \n",
       "0  https://hackernoon.com/@mrogati?source=tag_arc...  \n",
       "1  https://medium.com/@hristoborisov?source=tag_a...  \n",
       "2  https://medium.com/@laurentemma?source=tag_arc...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "frames =[]\n",
    "tags = ['ai', 'artificial-intelligence',\n",
    " 'blogging', 'business',\n",
    " 'data-science', 'design',\n",
    " 'education', 'entrepreneurship',\n",
    " 'health', 'humor',\n",
    " 'inspiration', 'javascript',\n",
    " 'leadership', 'life',\n",
    " 'life-lessons', 'love',\n",
    " 'machine-learning', 'marketing',\n",
    " 'motivation', 'personal-development',\n",
    " 'poetry', 'politics',\n",
    " 'productivity', 'programming',\n",
    " 'python', 'racism',\n",
    " 'science', 'self-improvement',\n",
    " 'software-engineering', 'startup',\n",
    " 'tech', 'technology',\n",
    " 'travel', 'web-design',\n",
    " 'web-development', 'writing']\n",
    "\n",
    "for tag in tags:\n",
    "    #all of the seperate scrapes from different tags\n",
    "    df = pd.read_csv(\"TAG_SCRAPES/medium_\"+tag+\".csv\")\n",
    "    frames.append(df)\n",
    "medium = pd.concat(frames)\n",
    "medium.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles scraped:  993318\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles scraped: \",medium.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Converting Strings to Floats\n",
    "\n",
    "Before we can work with the data we need to <b>convert the \"Claps\" column from string to float values</b>. Note that the Object datatype is non-numeric. There is also an issue with <b>Claps in the form of \"5.5K\", rather than \"5500\".</b>\n",
    "\n",
    "### Preview of DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title           object\n",
       "Subtitle        object\n",
       "Image            int64\n",
       "Author          object\n",
       "Publication     object\n",
       "Year             int64\n",
       "Month            int64\n",
       "Day              int64\n",
       "Tag             object\n",
       "Reading_Time     int64\n",
       "Claps           object\n",
       "Comment          int64\n",
       "url             object\n",
       "Author_url      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformatting Clap Information to Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clap dtype:  float64\n"
     ]
    }
   ],
   "source": [
    "#Claps entries higher than 999 are written \"5.5K\"\n",
    "# here we remove the \"K\", convert the string to float, then multiply by 1000.\n",
    "numeric_claps = []\n",
    "for x in medium.Claps:\n",
    "    if \"K\" in x:\n",
    "        numeric_claps.append(float(x[:-1])*1000)\n",
    "    else:\n",
    "        numeric_claps.append(x)\n",
    "medium[\"Claps\"] = numeric_claps\n",
    "medium[\"Claps\"] = pd.to_numeric(medium[\"Claps\"])\n",
    "print(\"Clap dtype: \", medium.dtypes[\"Claps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Removing Comment Entries\n",
    "Comment entries have been encoded into the data with the Comment column. Since these entries are not articles, I remove them in the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries to be removed:  62934\n",
      "Percentage of remaining data:  6.34 %\n"
     ]
    }
   ],
   "source": [
    "no_comm = medium[medium.Comment==0]\n",
    "no_comm = no_comm.drop([\"Comment\"], axis=1)\n",
    "print(\"Number of Entries to be removed: \", medium.shape[0]-no_comm.shape[0])\n",
    "print(\"Percentage of remaining data: \" ,round(((medium.shape[0]-no_comm.shape[0])/medium.shape[0])*100,2), \"%\")\n",
    "medium = no_comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Checking for Non Entries in the Data\n",
    "\n",
    "\n",
    "### All NaNs in Each Column\n",
    "We only have missing values in Title, Subtitle, or Publication. <b>NaNs in publication column because not all articles are published. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs\n",
      "Title                28418\n",
      "Subtitle            296936\n",
      "Image                    0\n",
      "Author                   3\n",
      "Publication         628957\n",
      "Year                     0\n",
      "Month                    0\n",
      "Day                      0\n",
      "Tag                      0\n",
      "Reading_Time             0\n",
      "\n",
      "Total Entries:   930384\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaNs\")\n",
    "for x in range(10):\n",
    "    print(\"%-15s %10d\" % (medium.columns.values[x], medium.iloc[:,x].isna().sum()))\n",
    "print()\n",
    "print(\"Total Entries:  \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN Title and Subtitle Entries\n",
    "Sometimes when scraping the archive page, Titles are in weird formats. The result, <b> some articles titles are scraped as subtitles</b>. This is not a big deal as we dont really \"need\" the Title data, it just bothers me. \n",
    "\n",
    "Here is a breakdown of the NonEntries in Title/SubTitle Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NaN Title Entries:  28418\n",
      "Entries with NaN Title but existing SubTitle:  16032\n",
      "Entries with neither title nor subtitle:  12386\n"
     ]
    }
   ],
   "source": [
    "#Total entries with no Title\n",
    "print(\"Total NaN Title Entries: \", medium[medium.Title.isnull()].shape[0])\n",
    "\n",
    "#Entries with no title but with a subtitle\n",
    "print(\"Entries with NaN Title but existing SubTitle: \",medium[(medium.Title.isnull() & medium.Subtitle.notnull())].shape[0])\n",
    "\n",
    "#Neither\n",
    "print(\"Entries with neither title nor subtitle: \", medium[(medium.Title.isnull() & medium.Subtitle.isnull())].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Removing Duplicate Articles (Same Tag)\n",
    "Duplicate articles have the same name, author,Tag. <b>Author will repost there article, or spam post it 3 times</b> \n",
    "\n",
    "The important thing to note is that we are looking for entries with identical Tags. We will deal with duplicates with different tags next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Strategy:</strong> \n",
    "1. Create a sub-dataframe with the [\"Title\", \"Author\",\"Tag\", \"Date\"] columns. \n",
    "2. Create a mask with df.duplicated(keep=\"first\") will mark all rows that duplicate the above three columns.\n",
    "3. Remove all rows marked True from Medium dframe (use the ~ operator on the mask to switch bool values).\n",
    "\n",
    "<strong>Result:</strong> Medium DataFrame will have all rows that are duplicates of title, author,Tag, and pub date removed. We will see how many rows this removes.\n",
    "\n",
    "#### TL;DR We are removing all but one of each spam-posted article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows removed:  21061\n",
      "Percentage of remaining data:  2.26 %\n",
      "Average Claps of spam-posted population:  148.6183467071839\n"
     ]
    }
   ],
   "source": [
    "dup = medium[medium.duplicated(subset=[\"Title\", \"Author\",\"Tag\"], keep=\"first\")] \n",
    "no_dup = medium[~medium.duplicated(subset=[\"Title\", \"Author\",\"Tag\"], keep=\"first\")]\n",
    "print(\"Number of Rows removed: \", medium.shape[0]-no_dup.shape[0])\n",
    "print(\"Percentage of remaining data: \", round(((medium.shape[0]-no_dup.shape[0])/medium.shape[0])*100,2),\"%\")\n",
    "print(\"Average Claps of spam-posted population: \",dup.Claps.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 3 Multi-posted Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14841</th>\n",
       "      <td>Want To Become A Multi-Millionaire? Do These 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Benjamin P. Hardy</td>\n",
       "      <td>Thrive Global</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>startup</td>\n",
       "      <td>21</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>https://medium.com/thrive-global/want-to-becom...</td>\n",
       "      <td>https://medium.com/@benjaminhardy?source=tag_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10627</th>\n",
       "      <td>30 Behaviors That Will Make You Unstoppable</td>\n",
       "      <td>A lot of people are good at what they do. Some...</td>\n",
       "      <td>1</td>\n",
       "      <td>Benjamin P. Hardy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>productivity</td>\n",
       "      <td>13</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>https://medium.com/@benjaminhardy/30-behaviors...</td>\n",
       "      <td>https://medium.com/@benjaminhardy?source=tag_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11655</th>\n",
       "      <td>30 Behaviors That Will Make You Unstoppable</td>\n",
       "      <td>A lot of people are good at what they do. Some...</td>\n",
       "      <td>1</td>\n",
       "      <td>Benjamin P. Hardy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>self-improvement</td>\n",
       "      <td>13</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>https://medium.com/@benjaminhardy/30-behaviors...</td>\n",
       "      <td>https://medium.com/@benjaminhardy?source=tag_a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "14841  Want To Become A Multi-Millionaire? Do These 1...   \n",
       "10627        30 Behaviors That Will Make You Unstoppable   \n",
       "11655        30 Behaviors That Will Make You Unstoppable   \n",
       "\n",
       "                                                Subtitle  Image  \\\n",
       "14841                                                NaN      1   \n",
       "10627  A lot of people are good at what they do. Some...      1   \n",
       "11655  A lot of people are good at what they do. Some...      1   \n",
       "\n",
       "                  Author    Publication  Year  Month  Day               Tag  \\\n",
       "14841  Benjamin P. Hardy  Thrive Global  2018      2    5           startup   \n",
       "10627  Benjamin P. Hardy            NaN  2017     11   22      productivity   \n",
       "11655  Benjamin P. Hardy            NaN  2017     11   22  self-improvement   \n",
       "\n",
       "       Reading_Time    Claps  \\\n",
       "14841            21  96000.0   \n",
       "10627            13  55000.0   \n",
       "11655            13  55000.0   \n",
       "\n",
       "                                                     url  \\\n",
       "14841  https://medium.com/thrive-global/want-to-becom...   \n",
       "10627  https://medium.com/@benjaminhardy/30-behaviors...   \n",
       "11655  https://medium.com/@benjaminhardy/30-behaviors...   \n",
       "\n",
       "                                              Author_url  \n",
       "14841  https://medium.com/@benjaminhardy?source=tag_a...  \n",
       "10627  https://medium.com/@benjaminhardy?source=tag_a...  \n",
       "11655  https://medium.com/@benjaminhardy?source=tag_a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup.sort_values(\"Claps\", ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = no_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "# Removing Duplicate Articles (Multi-tagged)\n",
    "Medium allows an  author to include 5 tags for each story.\n",
    "\n",
    "When we scraped the archive page, we scraped each individual tag. <b>As a result, stories will appear multiple times in our data (with different tags)</b>\n",
    "\n",
    "<strong>Strategy:</strong>\n",
    "1. One hot encode the Tag column.\n",
    "2. Search all entries for duplicate rows in [\"Title\", \"Author\", \"Date\"]\n",
    "3. Add the duplicate entries' one hot encodings together.\n",
    "4. Delete the Duplicates\n",
    "\n",
    "<strong>Result:</strong> A one hot encoded list of each articles tags. With duplicates removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are:  339394 Duplicated entries.\n",
      "Unique posts with multiple tags:  150604\n"
     ]
    }
   ],
   "source": [
    "medium = pd.get_dummies(medium, columns =[\"Tag\"])\n",
    "\n",
    "multi_tags = medium[medium.duplicated(subset=[\"Title\", \"Author\", \"Year\", \"Month\",\"Day\"], keep=False)]\n",
    "print(\"There are: \", multi_tags.shape[0], \"Duplicated entries.\")\n",
    "print(\"Unique posts with multiple tags: \", multi_tags.shape[0]- medium[medium.duplicated(subset=[\"Title\", \"Author\", \"Year\", \"Month\",\"Day\"], keep=\"last\")].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining each multitagged article into ONE row\n",
    "\n",
    "1. Combine the onehot encoded tags of each multiposted article into one entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = multi_tags.sort_values([\"Title\", \"Author\", \"Year\", \"Month\",\"Day\"]).reset_index()\n",
    "\n",
    "#Iterate over each row in the data frome\n",
    "for index, row in sort.iterrows():\n",
    "    if (index+1) == sort.shape[0]:\n",
    "        break\n",
    "    #For each row if the title and author and date are the same as the next row\n",
    "    if ((row[\"Title\"]==sort.iloc[index+1][\"Title\"]) and (row[\"Author\"]==sort.iloc[index+1][\"Author\"]) and (row[\"Year\"]==sort.iloc[index+1][\"Year\"]) and (row[\"Month\"]==sort.iloc[index+1][\"Month\"]) and (row[\"Day\"]==sort.iloc[index+1][\"Day\"])):\n",
    "        #Pass forward your tag encoding to the next row\n",
    "        sort.iloc[index+1, 13:]+=sort.iloc[index, 13:]\n",
    "        assert (sort.iloc[index+1,13:]<2).all(), \"Error at row %r\" % index\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2.Delete all multiposted tags from the original data\n",
    "\n",
    "3.Append the combined data from above to the end of the Medium dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries deleted:  188790\n",
      "Percentage of remaining data:  20.76 %\n"
     ]
    }
   ],
   "source": [
    "#save only merged OHE entries\n",
    "merged = sort[~sort.duplicated(subset=[\"Title\", \"Author\",\"Year\", \"Month\",\"Day\"], keep=\"last\")]\n",
    "merged = merged.drop([\"index\"], axis=1)\n",
    "print(\"Total entries deleted: \", sort.shape[0] - merged.shape[0])\n",
    "print(\"Percentage of remaining data: \" ,round(((sort.shape[0]-merged.shape[0])/medium.shape[0])*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all duplicates\n",
    "medium = medium[~medium.duplicated(subset=[\"Title\", \"Author\", \"Year\", \"Month\",\"Day\"], keep=False)]\n",
    "#Append the merged duplicate frame\n",
    "dframes = [medium, merged]\n",
    "#merge\n",
    "medium = pd.concat(dframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "How much data do we have after cleaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of after cleaning:  720533\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of after cleaning: \", medium.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium.to_csv(\"Medium_Clean.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
